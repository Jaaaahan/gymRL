# gymRL
 本人学习强化学习(PPO,DQN,SAC,DDPG等算法)，在gym环境下写的代码集。

 主要研究了PPO和DQN类算法，根据各个论文复现了如下改进:

-  PPO: dual-PPO, clip-PPO, use-RNN, attention etc.
-  DQN: rainbow DQN

在离散动作空间，我一般使用PPO算法。
因此我对离散和连续动作空间的代码探索主要在CartPole(PPO), Pentilum(PPO)两份代码进行，读者可以重点关注
